```python
# æŸ¥çœ‹å½“å‰æŒ‚è½½çš„æ•°æ®é›†ç›®å½•, è¯¥ç›®å½•ä¸‹çš„å˜æ›´é‡å¯ç¯å¢ƒåä¼šè‡ªåŠ¨è¿˜åŸ
# View dataset directory. 
# This directory will be recovered automatically after resetting environment. 
!ls /home/aistudio/data
```


```python
# æŸ¥çœ‹å·¥ä½œåŒºæ–‡ä»¶, è¯¥ç›®å½•ä¸‹çš„å˜æ›´å°†ä¼šæŒä¹…ä¿å­˜. è¯·åŠæ—¶æ¸…ç†ä¸å¿…è¦çš„æ–‡ä»¶, é¿å…åŠ è½½è¿‡æ…¢.
# View personal work directory. 
# All changes under this directory will be kept even after reset. 
# Please clean unnecessary files in time to speed up environment loading. 
!ls /home/aistudio/work
```


```python
# å¦‚æœéœ€è¦è¿›è¡ŒæŒä¹…åŒ–å®‰è£…, éœ€è¦ä½¿ç”¨æŒä¹…åŒ–è·¯å¾„, å¦‚ä¸‹æ–¹ä»£ç ç¤ºä¾‹:
# If a persistence installation is required, 
# you need to use the persistence path as the following: 
!mkdir /home/aistudio/external-libraries
# !pip install beautifulsoup4 -t /home/aistudio/external-libraries
```


```python
# åŒæ—¶æ·»åŠ å¦‚ä¸‹ä»£ç , è¿™æ ·æ¯æ¬¡ç¯å¢ƒ(kernel)å¯åŠ¨çš„æ—¶å€™åªè¦è¿è¡Œä¸‹æ–¹ä»£ç å³å¯: 
# Also add the following code, 
# so that every time the environment (kernel) starts, 
# just run the following code: 
import sys 
sys.path.append('/home/aistudio/external-libraries')
```

è¯·ç‚¹å‡»[æ­¤å¤„](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)æŸ¥çœ‹æœ¬ç¯å¢ƒåŸºæœ¬ç”¨æ³•.  <br>
Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. 

# 1 BERTæ¨¡å‹çš„åˆæ­¥è®¤è¯†

åŒå­¦ä»¬å¤§å®¶å¥½ï¼Œæˆ‘ä»¬çš„è¯¾ç¨‹å°±æ­£å¼å¼€å§‹äº†å•Šï¼ ä¸çŸ¥é“BERTï¼ˆPre-training of Deep Bidirectional Transformersï¼ŒåŸæ–‡é“¾æ¥ï¼šBERTï¼‰æ²¡æœ‰å…³ç³»ï¼Œè®©æˆ‘ä»¬æ¥çœ‹ä¸€äº›æ•°æ®ã€‚

è‡ªä»2018å¹´BERTæ¨¡å‹å‘å¸ƒä»¥æ¥ï¼ŒBERTæ¨¡å‹ä»…ç”¨ 2019 å¹´ä¸€å¹´çš„æ—¶é—´ï¼Œä¾¿ä»¥åŠ¿å¦‚ç ´ç«¹çš„å§¿æ€æˆä¸ºäº† NLP é¢†åŸŸé¦–å±ˆä¸€æŒ‡çš„çº¢äººï¼ŒBERT ç›¸å…³çš„è®ºæ–‡ä¹Ÿå¦‚æ¶Œæ½®èˆ¬å‘è¡¨å‡ºæ¥ã€‚2019 å¹´ï¼Œå¯è°“æ˜¯ NLP å‘å±•å†ç¨‹ä¸­å…·æœ‰é‡Œç¨‹ç¢‘æ„ä¹‰çš„ä¸€å¹´ï¼Œè€Œå…¶èƒŒåçš„æœ€å¤§åŠŸè‡£å½“å± BERT ï¼åœ¨NLPé¢†åŸŸï¼Œå¦‚æœæŠŠ2019å¹´ç§°ä¸ºâ€œBERTå¹´â€ä¹Ÿä¸ä¸ºè¿‡ã€‚ æ®ç»Ÿè®¡ï¼Œ2019ä»¥BERTä¸ºä¸»è¦å†…å®¹çš„è®ºæ–‡å‘è¡¨æ•°é‡è¿‘200ç¯‡ï¼Œå…·ä½“æ•°æ®å¯ä»¥çœ‹çœ‹ä¸‹é¢å›¾ç‰‡çš„githubé“¾æ¥å‘¦ã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/a9ac464e38a44044a65b33bf4e1ae99253e712727d974c9c9e4af65032f96733" width="800" />

å›¾ç‰‡å‡ºå¤„ï¼š[BERT_papers](http://github.com/nslatysheva/BERT_papers)ï¼Œç‚¹ç‚¹çœ‹ï¼Œé‡Œé¢æœ‰å½©è›‹ã€‚

# 2 BERTå‘å¸ƒä¹‹å‰NLPçš„çŠ¶æ€

åœ¨BERTæ¨¡å‹å‘å¸ƒä¹‹å‰ï¼ŒNLPä»»åŠ¡çš„è§£å†³æ–¹æ¡ˆæ˜¯åŸºäºword2vecè¿™æ ·çš„è¯ç‰¹å¾+RNNsç­‰ç½‘ç»œç»“æ„çš„è§£å†³æ–¹æ¡ˆã€‚ç”±äºRNNsæ¨¡å‹çš„ç‰¹å¾æå–èƒ½åŠ›ä¸è¶³ï¼Œä¸ºäº†æ»¡è¶³ä¸šåŠ¡æŒ‡æ ‡ï¼Œå¾€å¾€éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®æ‰èƒ½æ»¡è¶³ä¸Šçº¿éœ€æ±‚ã€‚è¿™æ ·ï¼Œå°ä¸€äº›çš„NLPå…¬å¸ï¼Œç”±äºç›¸å¯¹æ•°æ®çš„åŒ®ä¹ï¼Œéš¾ä»¥æ¨åŠ¨NLPä¸šåŠ¡ï¼Œè‡´ä½¿NLPæŠ€æœ¯çš„å‘å±•å¹¶æ²¡æœ‰åƒè®¡ç®—æœºè§†è§‰é¢†åŸŸé‚£ä¹ˆé¡ºåˆ©ã€‚ä¸è¿‡ï¼Œè‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰çš„ç ”ç©¶æœ¬èº«å°±æ˜¯äº’ç›¸äº¤å‰äº’ç›¸å½±å“çš„ï¼Œæ‰€ä»¥å°±æœ‰å­¦è€…åŸºäºå›¾åƒé¢†åŸŸçš„æ€æƒ³ï¼Œå°†NLPé—®é¢˜çš„æ€è·¯è½¬åŒ–ä¸ºé¢„è®­ç»ƒ+å¾®è°ƒçš„æ¨¡å¼ï¼Œå–å¾—äº†ä¼˜å¼‚çš„æˆç»©ï¼Œåœ¨BERTæ¨¡å‹å‘è¡¨ä¹‹å‰ï¼ŒELMoã€GPTå°±æ˜¯è¿™ä¸€æ¨¡å¼çš„å…¸å‹å¼€åˆ›è€…ã€‚

ELMoæå‡ºçš„é¢„è®­ç»ƒ+å¾®è°ƒçš„æ¨¡å¼ï¼Œå½“æ—¶åªæ˜¯ä¸ºäº†è§£å†³word2vecè¯å‘é‡ä¸èƒ½è¡¨è¾¾â€ä¸€è¯å¤šä¹‰â€œçš„é—®é¢˜æå‡ºæ¥çš„ã€‚å®ƒæ˜¯ä¸€ç§åŠ¨æ€è¯å‘é‡çš„æ€æƒ³ï¼Œä¸è¿‡è¿™ç§é¢„è®­ç»ƒ+å¾®è°ƒçš„æ¨¡å¼å€ŸåŠ©è¿ç§»å­¦ä¹ çš„æ€æƒ³ä¸ºåæ¥BERTçš„å‡ºç°æ‰“ä¸‹äº†ä¸€å®šçš„åŸºç¡€ï¼Œæœ¬ç« ä¸ä¼šå…·ä½“é˜è¿°ELMoçš„åŸç†ï¼Œå¦‚æœä½ è¿˜ä¸äº†è§£ELMoï¼Œæˆ‘å¼ºçƒˆå»ºè®®ä½ é˜…è¯»ä¸‹é¢çš„ææ–™æ¥è¡¥å……ç›¸å…³çš„çŸ¥è¯†ã€‚

ELMoç›¸å…³é˜…è¯»èµ„æ–™ï¼šï¼ˆ[ELMoåŸç†è§£æåŠç®€å•ä¸Šæ‰‹ä½¿ç”¨](https://zhuanlan.zhihu.com/p/51679783)ï¼Œä¸ç®¡ä½ çœ‹æ²¡çœ‹ï¼Œéƒ½è¦é—®ä¸€ä¸‹è‡ªå·±ä¸‹é¢è¿™é“æ€è€ƒé¢˜å•Šï¼å½“ç„¶ï¼Œé˜…è¯»èµ„æ–™é‡Œä¹Ÿèƒ½æ‰¾åˆ°ã€‚ğŸ˜ ï¼‰



ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œ2017å¹´Googleå‘å¸ƒäº†ç‰¹å¾æå–èƒ½åŠ›æ›´ä¸ºå¼ºå¤§çš„Transformerç½‘ç»œï¼Œè®ºæ–‡é“¾æ¥ï¼š[Attention is all you need](http://arxiv.org/abs/1706.03762)ã€‚Transformerä¸­çš„å…·ä½“ç»“æ„ä»¥åŠä»£ç éƒ½ä¼šåœ¨åé¢ç« èŠ‚ç»“åˆBERTè¯¦ç»†å‰–æï¼Œåœ¨æ­¤ä¸è¿‡å¤šä»‹ç»ã€‚

æœ‰äº†Transformerç½‘ç»œç»“æ„åï¼Œæ”¹é€ ELMoè§£å†³æ›´å¤šæ›´éš¾çš„é—®é¢˜ï¼Œæä¾›äº†ä¸€ä¸ªæ–¹å‘ã€‚

å¯¹äºè¿‘å¹´æ¥NLPé¢†åŸŸæ¨¡å‹å‘å±•çš„å†å²å¯ä»¥è§‚çœ‹ä¸‹å›¾ï¼Œè¯¥å›¾å‡ºè‡ªACL2019å¤§ä¼šæŠ¥å‘Šï¼ˆThe Bright Future of ACL/NLPï¼Œå¯ä»¥åœ¨è¯¾ç¨‹ä¸­ä¸‹è½½ï¼‰ã€‚

![](https://ai-studio-static-online.cdn.bcebos.com/da206850e9694cbb9e21af24cb0d7e50617565e980e64240a2bcc3bc0c5ef851)

ä¸è¿‡è¯è¯´å›æ¥ï¼Œç¬¬ä¸€ä¸ªä½¿ç”¨Transformerçš„é¢„è®­ç»ƒæ¨¡å‹ä¸æ˜¯bertï¼Œè€Œæ˜¯GPTã€‚æƒ³è¦è¿›ä¸€æ­¥äº†è§£GPTæ¨¡å‹çš„åŒå­¦ï¼Œå¯ä»¥é˜…è¯»è¡¥å……èµ„æ–™ï¼ˆOpenAI GPT: Generative Pre-Training for Language Understandingï¼‰ï¼Œå¦‚æœä½ ä¸äº†è§£Transformerç»“æ„ï¼Œæˆ‘å»ºè®®ä½ å…ˆä¸è¦é˜…è¯»ï¼Œç­‰å­¦å®Œåé¢è¯¾ç¨‹BERTä¸­Transformerçš„ç»†èŠ‚åï¼Œå†æ¥å“å‘³ä¸€ä¸‹GPTä¸BERTçš„ä¸åŒã€‚

æå‰é€éœ²ä¸€ä¸‹GPTå’ŒBERTçš„æœ€å¤§çš„ä¸åŒï¼ŒGPTé‡Œçš„åŸºæœ¬ç»“æ„æ˜¯ç”±å•å‘çš„Transformer-Decoderç»“æ„ç»„æˆï¼Œè€ŒBERTæ˜¯ç”±åŒå‘çš„Transformer-Encoderç»“æ„ç»„æˆã€‚

ä¸ç®¡æ˜¯ELMoã€GPTè¿˜æ˜¯BERTï¼Œä»–ä»¬æ”¹å˜è§£å†³NLPçš„é‡è¦æ€è·¯æ˜¯é¢„è®­ç»ƒ+å¾®è°ƒçš„æ¨¡å¼ã€‚å¦‚å›¾æ‰€ç¤ºï¼Œé¢„è®­ç»ƒ+å¾®è°ƒçš„æ¨¡å¼æ˜¯ä¸€ç§è¿ç§»å­¦ä¹ çš„æ€æƒ³ï¼Œé¢„è®­ç»ƒé˜¶æ®µå¯ä»¥ä½¿ç”¨å¤§è§„æ¨¡çš„æ•°æ®ï¼ˆæ¯”å¦‚wikiï¼‰ï¼Œä½¿å¾—ä¸€ä¸ªå¼ºå¤§çš„æ¨¡å‹å­¦ä¹ åˆ°å¤§é‡çš„çŸ¥è¯†ï¼Œè€Œä¸”è¿™äº›çŸ¥è¯†çš„å­¦ä¹ æ–¹å¼æ˜¯æ— ç›‘ç£çš„ã€‚é€šè¿‡é¢„è®­ç»ƒçš„å­¦ä¹ ä¹‹åï¼Œæ¨¡å‹å°±å·²ç»å…·å¤‡å¤§é‡çš„å…ˆéªŒçŸ¥è¯†ï¼Œåœ¨å¾®è°ƒé˜¶æ®µç»§ç»­ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„æ¨¡å‹å‚æ•°ï¼Œé‡‡ç”¨ä¸šåŠ¡è‡ªèº«æ ‡æ³¨æ•°æ®åœ¨æ­¤åŸºç¡€ä¸Šå®Œæˆæœ€åä¸€æ­¥çš„ç›‘ç£å­¦ä¹ ã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/4f8d130b390b4d5a82f065ff57029c9131e7dd7beb9b445da0dfc01cdeb3d7ba" width="500" />

# 3 å¸¦ä½ è¯»BERTåŸè®ºæ–‡

è€ƒéªŒå¤§å®¶çš„ç¯èŠ‚åˆ°äº†å•Šï¼Œæˆ‘ä»¬éœ€è¦ç²¾è¯»ä¸€ä¸‹BERTçš„åŸæ–‡ï¼Œæˆ‘ä¹Ÿå·²ç»å°†é‡è¦çš„ä¿¡æ¯åšäº†æ ‡æ³¨å’Œè§£é‡Šï¼Œå¤§å®¶æ‰“å¼€æ¥é˜…è¯»å§ï¼ˆé€€å›è¯¾ç¨‹ä¸»é¡µï¼Œæ‰“å¼€æœ‰æ ‡æ³¨çš„BERTåŸæ–‡ï¼‰ã€‚

æŠŠæ ‡æ³¨çš„åœ°æ–¹å…¨éƒ¨å¼„æ¸…æ¥šï¼Œå°±å¯ä»¥è¿›è¡Œä¸‹é¢çš„å­¦ä¹ äº†ï¼Œå¦‚æœæœ‰ä»€ä¹ˆç–‘é—®å¯ä»¥åœ¨ç¾¤é‡Œå’¨è¯¢å•Šï¼Œä¸€ä¸ªæ–°çš„ç®—æ³•ï¼Œç†è®ºå•ƒå®Œï¼Œåœ¨æŠŠæºç åƒé€ï¼Œæ‰ç®—çœŸçš„æŒæ¡ï¼Œå¸Œæœ›å¤§å®¶å¤šæ³¨æ„ç»†èŠ‚ã€‚



<img src="https://ai-studio-static-online.cdn.bcebos.com/95d0106a8b3e43bfba4ddfb8ff618366d1ff9c9324254e71af6ca7cbd7ad4496" width="600" />

# 4 BERTå‘å¸ƒæ—¶çš„æˆç»©

BERTå½“å¹´å‘è¡¨æ—¶å°±åœ¨SQuAD v1.1ä¸Šï¼Œè·å¾—äº†93.2ï¼…çš„ F1 åˆ†æ•°ï¼Œè¶…è¿‡äº†ä¹‹å‰æœ€é«˜æ°´å‡†çš„åˆ†æ•°91.6ï¼…ï¼ŒåŒæ—¶è¶…è¿‡äº†äººç±»çš„åˆ†æ•°91.2%ã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/318a6d6718ac45c796864e08cd89151a5b92955427f04be084d22fef9583eacb" width="700" />

BERT è¿˜åœ¨æå…·æŒ‘æˆ˜æ€§çš„ GLUE åŸºå‡†æµ‹è¯•ä¸­å°†å‡†ç¡®æ€§çš„æ ‡å‡†æé«˜äº†7.6ï¼…ã€‚è¿™ä¸ªåŸºå‡†æµ‹è¯•åŒ…å« 9 ç§ä¸åŒçš„è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNLUï¼‰ä»»åŠ¡ã€‚åœ¨è¿™äº›ä»»åŠ¡ä¸­ï¼Œå…·æœ‰äººç±»æ ‡ç­¾çš„è®­ç»ƒæ•°æ®è·¨åº¦ä» 2,500 ä¸ªæ ·æœ¬åˆ° 400,000 ä¸ªæ ·æœ¬ä¸ç­‰ã€‚BERT åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­éƒ½å¤§å¤§æé«˜äº†å‡†ç¡®æ€§ã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/8729ae9d54b74236aa56932a2e282ad0b50d18ef8eae402c802ae2d1fb3b8e8b" width="800" />

ä¸Šè¿°çš„å¾®è°ƒä»»åŠ¡ä»‹ç»å¦‚ä¸‹è¡¨

- MNLIï¼šç»™å®šä¸€ä¸ªå‰æ (Premise) ï¼Œæ ¹æ®è¿™ä¸ªå‰æå»æ¨æ–­å‡è®¾ (Hypothesis) ä¸å‰æçš„å…³ç³»ã€‚è¯¥ä»»åŠ¡çš„å…³ç³»åˆ†ä¸ºä¸‰ç§ï¼Œè•´å«å…³ç³» (Entailment)ã€çŸ›ç›¾å…³ç³» (Contradiction) ä»¥åŠä¸­ç«‹å…³ç³» (Neutral)ã€‚æ‰€ä»¥è¿™ä¸ªé—®é¢˜æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦åšçš„æ˜¯å»å‘æ˜å‰æå’Œå‡è®¾è¿™ä¸¤ä¸ªå¥å­å¯¹ä¹‹é—´çš„äº¤äº’ä¿¡æ¯ã€‚
- QQPï¼šåŸºäºQuoraï¼Œåˆ¤æ–­ Quora ä¸Šçš„ä¸¤ä¸ªé—®é¢˜å¥æ˜¯å¦è¡¨ç¤ºçš„æ˜¯ä¸€æ ·çš„æ„æ€ã€‚
- QNLIï¼šç”¨äºåˆ¤æ–­æ–‡æœ¬æ˜¯å¦åŒ…å«é—®é¢˜çš„ç­”æ¡ˆï¼Œç±»ä¼¼äºæˆ‘ä»¬åšé˜…è¯»ç†è§£å®šä½é—®é¢˜æ‰€åœ¨çš„æ®µè½ã€‚
- STS-Bï¼šé¢„æµ‹ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼æ€§ï¼ŒåŒ…æ‹¬5ä¸ªçº§åˆ«ã€‚
- MRPCï¼šä¹Ÿæ˜¯åˆ¤æ–­ä¸¤ä¸ªå¥å­æ˜¯å¦æ˜¯ç­‰ä»·çš„ã€‚
- RTEï¼šç±»ä¼¼äºMNLIï¼Œä½†æ˜¯åªæ˜¯å¯¹è•´å«å…³ç³»çš„äºŒåˆ†ç±»åˆ¤æ–­ï¼Œè€Œä¸”æ•°æ®é›†æ›´å°ã€‚
- SWAGï¼šä»å››ä¸ªå¥å­ä¸­é€‰æ‹©ä¸ºå¯èƒ½ä¸ºå‰å¥ä¸‹æ–‡çš„é‚£ä¸ªã€‚
- SST-2ï¼šç”µå½±è¯„ä»·çš„æƒ…æ„Ÿåˆ†æã€‚
- CoLAï¼šå¥å­è¯­ä¹‰åˆ¤æ–­ï¼Œæ˜¯å¦æ˜¯å¯æ¥å—çš„ï¼ˆAcceptableï¼‰ã€‚

# 5 BERTæ¨¡å‹çš„æ ¸å¿ƒæ¶æ„

é€šè¿‡ä¸Šé¢ç« èŠ‚çš„å­¦ä¹ ï¼Œå¤§å®¶å¯¹BERTåº”è¯¥æœ‰äº†åŸºæœ¬çš„è®¤è¯†ã€‚åœ¨è¿è¡Œæœ€åä¸€æ®µä»£ç æ—¶åº”è¯¥å·²ç»å‘ç°ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†[Transformersé¢„è®­ç»ƒæ¨¡å‹åº“](https://github.com/huggingface/transformers)æ¥å®ç°BERTçš„åŠŸèƒ½ï¼Œæ‰€ä»¥æˆ‘ä»¬è¿™èŠ‚è¯¾çš„ä»£ç ä¾ç„¶ä»¥æ­¤ä¸ºåŸºç¡€ã€‚

åœ¨workæ–‡ä»¶å¤¹ä¸‹å·²ç»ä¸ºå¤§å®¶å‡†å¤‡äº†transformersåº“çš„å‹ç¼©åŒ…ï¼Œå¯ä»¥åœ¨ç»ˆç«¯ä¸­è‡ªè¡Œè§£å‹ã€‚

ä»ç†è®ºçš„è§’åº¦çœ‹ï¼Œæƒ³è¦äº†è§£BERTçš„æ¨¡å‹ç»“æ„ï¼Œéœ€è¦è¡¥å……Transformerï¼ˆä»¥è‡ªæ³¨æ„åŠ›ä¸ºä¸»ï¼‰ç»“æ„çš„ç›¸å…³çŸ¥è¯†ï¼Œè®ºæ–‡é“¾æ¥ä¸ŠèŠ‚å·²ç»ç»™å‡ºã€‚ä¸è¿‡BERTå¹¶æ²¡æœ‰é‡‡ç”¨æ•´ä¸ªçš„Transformerç»“æ„ï¼Œä»…ä½¿ç”¨äº†Transformerç»“æ„é‡Œçš„Encoderéƒ¨åˆ†ã€‚BERTå°†å¤šå±‚çš„Encoderæ­å»ºä¸€èµ·ç»„æˆäº†å®ƒçš„åŸºæœ¬ç½‘ç»œç»“æ„ï¼Œæœ¬èŠ‚è¯¾æˆ‘ä»¬ä¼šä»BERTçš„æºä»£ç è§’åº¦åˆ†æBERTçš„æ ¸å¿ƒã€‚

ä¸‹é¢æˆ‘ä»¬çœ‹çœ‹æ•´ä¸ªçš„BERTæ¨¡å‹æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œå¤§ä½“ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/dc50f60f212f4f7ea0c2a490179e8795323399aa27414b31a1f825a51f044909" width="500" />

## 5.1 BertEncoder

çº¢è‰²æ¡†åœˆå‡ºçš„éƒ¨åˆ†å°±æ˜¯BERTçš„æ•´ä¸ªæ ¸å¿ƒç½‘ç»œç»“æ„ï¼Œæˆ‘ä»¬ç®¡ä»–å«åšBERT Encoderï¼Œè¯¥éƒ¨åˆ†ä»£ç åœ¨work/transformers/src/transformers/modeling_bert.pyä¸­ï¼ˆtransformersè§£å‹åè·¯å¾„ï¼‰ï¼Œç›¸åº”çš„ç±»æ˜¯BertEncoderï¼Œä»£ç å¦‚ä¸‹ã€‚

æœ¬èŠ‚è¯¾é‡‡ç”¨çš„æºç å‡ºè‡ªTransformers 3.4.0ï¼ŒåŒå­¦å¯ä»¥è‡ªå·±å»githubä¸Špullï¼Œä¹Ÿå¯ä»¥çœ‹workç›®å½•ä¸‹çš„ä»£ç 


```python
import torch
from torch import nn
```


```python
class BertEncoder(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.config = config
        # ç”±å¤šå±‚BertLayerï¼ˆTransformer Encoderï¼‰ç»„æˆï¼Œè®ºæ–‡ä¸­ç»™å‡ºï¼Œbert-baseæ˜¯12å±‚ï¼Œbert-largeæ˜¯24å±‚ï¼Œä¸€å±‚ç»“æ„å°±å¦‚ä¸Šå›¾ä¸­è“è‰²æ¡†é‡Œçš„ç»“æ„
        # config.num_hidden_layers) = 12 or 24
        # nn.ModuleListç§°ä¹‹ä¸ºå®¹å™¨ï¼Œä½¿ç”¨æ–¹æ³•å’Œpythoné‡Œçš„listç±»ä¼¼
        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])
```

## 5.2 BertLayer

<img src="https://ai-studio-static-online.cdn.bcebos.com/e3f69ac3c0d24bfa930bf46006c5ffee247ef51ed48b46d5b9bc697fc409aad9" width="700" />

é€šè¿‡ä¸Šé¢çš„ä»£ç èƒ½å¤Ÿçœ‹å‡ºï¼ŒBertEncoderæ˜¯ç”±å¤šå±‚BertLayerå åŠ è€Œæˆï¼Œæˆ‘ä»¬æŠŠBertLayerè¿™ä¸ªç»“æ„å•ç‹¬æ‹¿å‡ºæ¥ï¼Œå¦‚ä¸Šå›¾ä¸­å³åŠéƒ¨åˆ†æ‰€ç¤ºã€‚å®ƒçš„ä»£ç ç»“æ„å¦‚ä¸‹ã€‚


```python
class BertLayer(nn.Module):
    def __init__(self, config):
        super().__init__()
        # è¿™å¥è¯æ˜¯æœ€æ–°æ¨¡å‹Reformerç”¨æ¥é™ä½FFNå†…å­˜å ç”¨ç©ºé—´å¤§çš„é—®é¢˜ï¼ŒBERTæ¨¡å‹ä¸ç”¨è€ƒè™‘
        self.chunk_size_feed_forward = config.chunk_size_feed_forward
        # Reformeræ‰ä¼šç”¨ï¼Œæ­¤å¤„ä¸ç”¨
        self.seq_len_dim = 1
        # BertAttentionä¸ºå›¾ä¸­çš„Multi-Head Attentionç»“æ„+å…¶ä¸Šé¢ç¬¬ä¸€ä¸ªAdd & Normç»“æ„
        self.attention = BertAttention(config)
        # å¦‚æœéœ€è¦æœ‰ç”¨åˆ°Transformerçš„decoderç»“æ„ï¼Œå°±éœ€è¦è·‘ä¸‹é¢11-14è¡Œä»£ç ï¼Œä½†çº¯BERTæ¨¡å‹æ˜¯ä¸è¦çš„
        self.add_cross_attention = config.add_cross_attention
        if self.add_cross_attention:
            assert self.is_decoder, f"{self} should be used as a decoder model if cross attention is added"
            self.crossattention = BertAttention(config)
        # å›¾ä¸­çš„Feed Forwardç»“æ„
        self.intermediate = BertIntermediate(config)
        # å›¾ä¸­Feed Forwardç»“æ„ä¸Šé¢çš„Add & Normç»“æ„
        self.output = BertOutput(config)
```

BertLayerç±»çš„åˆå§‹å®šä¹‰ä¸Šé¢å·²ç»ç»™å‡ºï¼Œä¸‹é¢é€šè¿‡BertLayerç±»ä¸­çš„forwardå‡½æ•°çœ‹ä¸‹æ•´ä¸ªæ¨¡å‹çš„è¿è¡Œæµç¨‹ã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/e30904ae33d94e7cb50a7d6975aa36f65f4729718156449cbc78193ebd848237" width="600" />


```python
def forward(
    self,
    hidden_states,
    attention_mask=None,
    head_mask=None,
    encoder_hidden_states=None,
    encoder_attention_mask=None,
    output_attentions=False,
):
    # BertAttentionï¼Œä¼ å‚è¿›å»çš„maskåç»­ä¼šæœ‰è¯¦ç»†è§£é‡Š
    self_attention_outputs = self.attention(
        hidden_states,
        attention_mask,
        head_mask,
        output_attentions=output_attentions,
    )
    # self_attention_outputs[0]æ˜¯é€šè¿‡å¤šå¤´è‡ªæ³¨æ„åŠ›åçš„è¾“å‡ºç»“æœ
    attention_output = self_attention_outputs[0]
    # self_attention_outputs[1]æ˜¯å­æ³¨æ„åŠ›è®¡ç®—è¿‡ç¨‹ä¸­äº§ç”Ÿçš„attention weights
    outputs = self_attention_outputs[1:]
    
    """
    æ³¨é‡Šæ‰çš„è¿™æ®µä»£ç åœ¨BERTé‡Œæ˜¯ä¸ç”¨çš„ï¼Œåœ¨ä¸€äº›ç”¨äºç”Ÿæˆå¼ä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ä¼šä½¿ç”¨ï¼Œå…¶å®è¿™ä¸ªåœ°æ–¹æ˜¯èƒ½ä½“ç°å‡ºBERTå’ŒGPTçš„ä¸åŒã€‚

    if self.is_decoder and encoder_hidden_states is not None:
        assert hasattr(
            self, "crossattention"
        ), f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers by setting `config.add_cross_attention=True`"
        cross_attention_outputs = self.crossattention(
            attention_output,
            attention_mask,
            head_mask,
            encoder_hidden_states,
            encoder_attention_mask,
            output_attentions,
        )
        attention_output = cross_attention_outputs[0]
        outputs = outputs + cross_attention_outputs[1:]  # add cross attentions if we output attention weights
    """
    # è¿™æ®µä»£ç é‡Œçš„chunkingéƒ¨åˆ†ä¸æ˜¯ç»™BERTç”¨çš„ï¼Œä½†æ˜¯æºç æŠŠBertIntermediateã€BertOutputéƒ½å°è£…åˆ°é‡Œé¢äº†ï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥çœ‹feed_forward_chunkè¿™ä¸ªå‡½æ•°å°±å¯ä»¥äº†
    layer_output = apply_chunking_to_forward(
        self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output
    )
    outputs = (layer_output,) + outputs
    return outputs

def feed_forward_chunk(self, attention_output):
    # BertIntermediateï¼Œç»“æ„è§å›¾
    intermediate_output = self.intermediate(attention_output)
    # BertOutputï¼Œç»“æ„è§å›¾
    layer_output = self.output(intermediate_output, attention_output)
    return layer_output
```

## 5.3 BertAttention

æ‹†åˆ°è¿™é‡Œä¸èƒ½åœï¼Œæˆ‘ä»¬è¿˜è¦ç»§ç»­æ‹†è§£ï¼Œæ‰¾åˆ°BERTæœ€æ ¸å¿ƒçš„ä»£ç ã€‚

æˆ‘ä»¬ç»§ç»­é‡‡ç”¨å€’åºæ‹†è§£çš„æ­¥éª¤åˆ†ææ¨¡å‹çš„æºç ï¼ŒBertAttentionå¯ä»¥æ‹†åˆ†BertSelfAttentionå’ŒBertSelfOutputä¸¤éƒ¨åˆ†ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚


```python
class BertAttention(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.self = BertSelfAttention(config)
        self.output = BertSelfOutput(config)
        # pruned_headsæ“ä½œå¾ˆæœ‰æ„æ€ï¼Œæ­¤å¤„å¯ä»¥æ‰©å±•é˜…è¯»ï¼Œè§ä¸‹é¢æ‰©å±•ã€‚å¦‚æœä»…äº†è§£BERTæœ€åŸºæœ¬çš„ï¼Œå¯ä»¥ä¸ç”¨çœ‹ã€‚
        self.pruned_heads = set()
```

æ‰©å±•é˜…è¯»ï¼šTransformerä¸­multi-headçš„æ¯ä¸ªheadåˆ°åº•åœ¨å¹²å˜›ï¼Ÿå¦‚æœæœ‰æ‰“é…±æ²¹çš„headæ˜¯å¦å¯ä»¥ç›´æ¥ä¸¢æ‰ï¼Ÿå…·ä½“å¯ä»¥å»¶ä¼¸é˜…è¯»[Are Sixteen Heads Really Better than One?](http://arxiv.org/pdf/1905.10650.pdf)ã€‚

å¥½çš„ï¼Œåˆ°è¿™ä½ç½®ï¼Œæœ€ä¸ºé‡è¦çš„self attentionï¼ˆè‡ªæ³¨æ„åŠ›ï¼‰ç»“æ„ç»ˆäºå‡ºç°äº†ï¼Œå¤§å®¶è¦ä»”ç»†é˜…è¯»å•Šï¼Œæˆ‘ä»¬å…ˆçœ‹çœ‹è‡ªæ³¨æ„åŠ›çš„åŸç†å›¾ã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/d899c3a39d4343afb3402e9e2ea70673e3d068625bbc4450aae53f7907cb79d4" width="600" />

Self-Attentionåœ¨æ•´ä¸ªTransformerç»“æ„ä¸­æ˜¯æœ€é‡è¦çš„åŸºæœ¬ç»“æ„å•å…ƒï¼Œæ•´ä¸ªè®¡ç®—è¿‡ç¨‹å›´ç»•ç€ä¸€ä¸ªå…¬å¼å±•å¼€ã€‚
$$
Attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt{d_k}})V
$$
Kã€Qã€Vä¸‰ä¸ªå‘é‡æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€šè¿‡tokençš„embeddingä¸ä¸‰ä¸ªä¸åŒçš„æƒé‡çŸ©é˜µåˆ†åˆ«ç›¸ä¹˜å¾—åˆ°çš„ï¼Œé€šè¿‡Self-Attentionçš„è®¡ç®—è¿‡ç¨‹åå®Œæˆä¸Šå›¾å·¦åŠè¾¹çš„ç»“æ„ã€‚

ä¸‹å›¾æ‹¿Thinking Machinesä¸€ä¸ªå¥å­å±•ç¤ºäº†æ•´ä¸ªçš„è‡ªæ³¨æ„åŠ›è®¡ç®—è¿‡ç¨‹ã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/46871d1ea8844adfbc9ac21612499b4d86493bf9a3db4b1393ac19a5c6ad0dcf" width="600" />

ä¸Šå›¾å‡ºå¤„ï¼š[http://jalammar.github.io/illustrated-transformer/](http://jalammar.github.io/illustrated-transformer/)ï¼Œå› ä¸ºä¸Šå›¾åªæ˜¯ä¸€æ­¥è®¡ç®—çš„å±•ç¤ºï¼Œæ•´ä¸ªè‡ªæ³¨æ„åŠ›è®¡ç®—æ˜¯éœ€è¦å¯¹æ¯ä¸ªtokenéƒ½è¿›è¡Œä¸€éã€‚å…³äºæ•´ä¸ªè¿‡ç¨‹çš„å½¢è±¡å±•ç¤ºï¼Œå¤§å®¶ç›´æ¥ç²¾è¯»è¿™ç¯‡åšå®¢å°±å¯ä»¥äº†ã€‚



```python
import math

class BertSelfAttention(nn.Module):
    def __init__(self, config):
        super().__init__()
        # hidden_sizeæ˜¯èƒ½æ•´é™¤å¤´æ•°çš„ï¼Œå¦åˆ™å°±ä¼šæŠ¥é”™ï¼ŒBERT-baseé‡Œhidden_sizeä¸º768
        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, "embedding_size"):
            raise ValueError(
                "The hidden size (%d) is not a multiple of the number of attention "
                "heads (%d)" % (config.hidden_size, config.num_attention_heads)
            )
        # å¤šå¤´çš„å¤´æ•°
        self.num_attention_heads = config.num_attention_heads
        # æ¯ä¸ªå¤´çš„ç»´åº¦
        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)
        self.all_head_size = self.num_attention_heads * self.attention_head_size
        
        # 
        self.query = nn.Linear(config.hidden_size, self.all_head_size)
        self.key = nn.Linear(config.hidden_size, self.all_head_size)
        self.value = nn.Linear(config.hidden_size, self.all_head_size)

        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)

    def transpose_for_scores(self, x):
        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)
        x = x.view(*new_x_shape)
        return x.permute(0, 2, 1, 3)

    def forward(
        self,
        hidden_states,
        attention_mask=None,
        head_mask=None,
        encoder_hidden_states=None,
        encoder_attention_mask=None,
        output_attentions=False,
    ):
        mixed_query_layer = self.query(hidden_states)

        # If this is instantiated as a cross-attention module, the keys
        # and values come from an encoder; the attention mask needs to be
        # such that the encoder's padding tokens are not attended to.
        if encoder_hidden_states is not None:
            mixed_key_layer = self.key(encoder_hidden_states)
            mixed_value_layer = self.value(encoder_hidden_states)
            attention_mask = encoder_attention_mask
        else:
            mixed_key_layer = self.key(hidden_states)
            mixed_value_layer = self.value(hidden_states)

        query_layer = self.transpose_for_scores(mixed_query_layer)
        key_layer = self.transpose_for_scores(mixed_key_layer)
        value_layer = self.transpose_for_scores(mixed_value_layer)

        # Take the dot product between "query" and "key" to get the raw attention scores.
        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
        attention_scores = attention_scores / math.sqrt(self.attention_head_size)
        
        if attention_mask is not None:
            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)
            # åŒå­¦ä»¬æƒ³ä¸€æƒ³è¿™ä¸€æ­¥åŠ çš„maskçš„ä½œç”¨ï¼Ÿ
            attention_scores = attention_scores + attention_mask 

        # Normalize the attention scores to probabilities.
        attention_probs = nn.Softmax(dim=-1)(attention_scores)

        # This is actually dropping out entire tokens to attend to, which might
        # seem a bit unusual, but is taken from the original Transformer paper.
        attention_probs = self.dropout(attention_probs)

        # Mask heads if we want to
        if head_mask is not None:
            attention_probs = attention_probs * head_mask

        context_layer = torch.matmul(attention_probs, value_layer)

        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()
        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)
        context_layer = context_layer.view(*new_context_layer_shape)

        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)
        return outputs
```


```python
class Config:
    def __init__(self):
        self.hidden_size = 768
        self.num_attention_heads = 12
        self.attention_probs_dropout_prob = 0.1

config = Config()
bertSelfAttention = BertSelfAttention(config)
input_tensor = torch.ones([2, 5, 768])
output_tensor = bertSelfAttention(input_tensor)
print(output_tensor)
```

![](https://ai-studio-static-online.cdn.bcebos.com/7fcd9d9ff30344f6ba42027540b10239e49dae940a5e4a8987876845c5d13c5a)

BERTä¸­æœ€é‡è¦çš„æ¨¡å‹ç»†èŠ‚ï¼Œæˆ‘ä»¬å°±æ‹†è§£å®Œäº†ï¼Œå…¶ä»–çš„ä»£ç å°±æ¯”è¾ƒå¥½ç†è§£äº†ï¼Œå¤§å®¶ç¨å¾®å›é¡¾ä¸‹ä¸Šå›¾çš„è¿‡ç¨‹ï¼Œå°±å¯ä»¥ç»§ç»­äº†ã€‚

çœ‹å®ŒBertSelfAttentionåï¼Œæˆ‘ä»¬çœ‹ä¸‹BertSelfOutputåˆ°åº•æ˜¯ä»€ä¹ˆå‘¢ï¼Œå…¶å®å®ƒå°±æ˜¯BertSelfAttentionä¸Šé¢çš„Add & Normå±‚ï¼Œå®ƒæ˜¯é‡‡ç”¨äº†æ®‹å·®ç»“æ„å¹¶è¿›è¡Œå±‚çº§å½’ä¸€åŒ–çš„æ“ä½œã€‚

å…³äºæ®‹å·®ç»“æ„ï¼Œå®ƒä¸»è¦æ˜¯è§£å†³ç¥ç»ç½‘ç»œæ¢¯åº¦æ¶ˆå¤±çš„ç°è±¡ï¼Œå¯ä»¥å‚è€ƒcvé¢†åŸŸä¸­çš„ä¸€äº›è§£é‡Šï¼Œå¦‚[ä¸ºä»€ä¹ˆResNetå’ŒDenseNetå¯ä»¥è¿™ä¹ˆæ·±ï¼Ÿä¸€æ–‡è¯¦è§£æ®‹å·®å—ä¸ºä½•æœ‰åŠ©äºè§£å†³æ¢¯åº¦å¼¥æ•£é—®é¢˜](https://zhuanlan.zhihu.com/p/28124810)ã€‚å…·ä½“çš„æ“ä½œå¦‚ä¸‹é¢ä»£ç ã€‚
```
hidden_states = self.LayerNorm(hidden_states + input_tensor)
# hidden_states + input_tensorå®ç°äº†ä¸€ä¸ªæ®‹å·®çš„æ“ä½œ
```
é™¤äº†æ®‹å·®ç»“æ„ï¼ŒåŒæ—¶å¢åŠ äº†ä¸€ä¸ªLayerNormå®ç°å±‚çº§å½’ä¸€åŒ–æ“ä½œï¼Œå…³äºLayerNormï¼Œå¯ä»¥ç ”ç©¶ä¸‹[è¯¦è§£æ·±åº¦å­¦ä¹ ä¸­çš„Normalizationï¼ŒBN/LN/WN](https://zhuanlan.zhihu.com/p/33173246)ã€‚



```python
# BertSelfOutputä»£ç å¦‚ä¸‹ï¼Œå¯ä»¥çœ‹ä¸‹å…·ä½“æ˜¯æ€ä¹ˆåšçš„Add & Norm
class BertSelfOutput(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.dense = nn.Linear(config.hidden_size, config.hidden_size)
        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)
        self.dropout = nn.Dropout(config.hidden_dropout_prob)

    def forward(self, hidden_states, input_tensor):
        hidden_states = self.dense(hidden_states)
        hidden_states = self.dropout(hidden_states)
        hidden_states = self.LayerNorm(hidden_states + input_tensor)
        return hidden_states
```

## 5.4 Feed-Forward Network

Encoderä¸­å­˜åœ¨çš„å¦ä¸€ä¸ªç»“æ„æ˜¯å‰é¦ˆç¥ç»ç½‘ç»œï¼Œä¹Ÿå°±æ˜¯Feed-Forward Networkï¼Œå®ƒçš„ä½œç”¨æ˜¯åŠ æ·±æˆ‘ä»¬çš„ç½‘ç»œç»“æ„ã€‚FFNå±‚åŒ…æ‹¬ä¸¤ä¸ªçº¿æ€§æ“ä½œï¼Œä¸­é—´æœ‰ä¸€ä¸ª ReLU æ¿€æ´»å‡½æ•°ï¼Œå¯¹åº”åˆ°å…¬å¼çš„å½¢å¼ä¸ºï¼š

$$FFN(x) = \max(0, xW_1+b_1)W_2 + b2$$

å…¶å®ï¼ŒFFNçš„åŠ å…¥å¼•å…¥äº†éçº¿æ€§(ReLuç­‰æ¿€æ´»å‡½æ•°)ï¼Œå˜æ¢äº†attention outputçš„ç©ºé—´, ä»è€Œå¢åŠ äº†æ¨¡å‹çš„è¡¨ç°èƒ½åŠ›ã€‚æŠŠFFNå»æ‰æ¨¡å‹ä¹Ÿæ˜¯å¯ä»¥ç”¨çš„ï¼Œä½†æ˜¯æ•ˆæœå·®äº†å¾ˆå¤šã€‚

ä»£ç è§BertIntermediateç±»ã€‚


```python
class BertIntermediate(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)
        if isinstance(config.hidden_act, str):
            # ACT2FNæ˜¯ä¸€ä¸ªå¯é…ç½®çš„æ¿€æ´»å‡½æ•°ï¼Œæœ‰RELUç­‰
            self.intermediate_act_fn = ACT2FN[config.hidden_act]
        else:
            self.intermediate_act_fn = config.hidden_act

    def forward(self, hidden_states):
        # ç¬¬ä¸€å±‚å…¨è¿æ¥
        hidden_states = self.dense(hidden_states)
        # ç¬¬ä¸€å±‚å…¨è¿æ¥çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œç¬¬äºŒå±‚å…¨è¿æ¥åšåˆ°äº†BertOutputé‡Œ
        hidden_states = self.intermediate_act_fn(hidden_states)
        return hidden_states
```

BertIntermediateå±‚ä¸Šé¢æ˜¯æœ€åä¸€å±‚BertOutputï¼Œä¸»è¦æ˜¯ä¸ºäº†å®ŒæˆFFNçš„ç¬¬äºŒå±‚å…¨è¿æ¥æ“ä½œå’Œæœ€åçš„Add & Normã€‚


```python
class BertOutput(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)
        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)
        self.dropout = nn.Dropout(config.hidden_dropout_prob)

    def forward(self, hidden_states, input_tensor):
        # FFNçš„ç¬¬äºŒå±‚çº¿æ€§å…¨è¿æ¥
        hidden_states = self.dense(hidden_states)
        # å®é™…ä»£ç ä¸­ä¼šæ·»åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆ
        hidden_states = self.dropout(hidden_states)
        # æœ€åçš„Add & Norm
        hidden_states = self.LayerNorm(hidden_states + input_tensor)
        return hidden_states
```

## 5.5 Mask

é™¤äº†Encoderçš„æ•´ä½“ä»£ç ä¹‹å¤–ï¼Œè´¯ç©¿å§‹ç»ˆçš„è¿˜æœ‰ä¸€ä¸ªç»†èŠ‚ï¼Œå°±æ˜¯ä»£ç ä¸­æœ‰å¾ˆå¤šçš„Maskæ“ä½œï¼Œé‚£ä»–ä»¬éƒ½æ˜¯åšä»€ä¹ˆçš„å‘¢ï¼Ÿ

åœ¨work/transformers/src/transformers/modeling_bert.pyä¸­å¯ä»¥æŸ¥åˆ°class BertModelï¼Œå…¶ä¸­

```
self.encoder = BertEncoder(config)
```
æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å­˜åœ¨å¾ˆå¤šçš„maskã€‚


```python
encoder_outputs = self.encoder(
            embedding_output,
            attention_mask=extended_attention_mask,
            head_mask=head_mask,
            encoder_hidden_states=encoder_hidden_states,
            encoder_attention_mask=encoder_extended_attention_mask,
            output_attentions=output_attentions,
            output_hidden_states=output_hidden_states,
            return_dict=return_dict,
        )
```

Maskè¡¨ç¤ºæ©ç ï¼Œå®ƒæ˜¯å¯¹æŸäº›å€¼è¿›è¡Œæ©ç›–ï¼Œè®©å…¶ä¸å‚åŠ è®¡ç®—ã€‚Transformeræ¨¡å‹ä¸­æ¶‰åŠåˆ°ä¸¤ç§maskï¼Œä¸€ç§æ˜¯padding maskï¼Œä¸€ç§æ˜¯sequence maskåªå­˜åœ¨decoderä¸­ã€‚ã€‚padding maskæ˜¯åœ¨encoderå’Œdecoderä¸­éƒ½å­˜åœ¨çš„ï¼Œè€Œsequence maskåªå­˜åœ¨decoderä¸­ã€‚

å¯¹äºè¿™ä¸¤ç§maskæ˜¯æ€ä¹ˆè®¡ç®—çš„ï¼Œå¯ä»¥å‚ç…§work/transformers/src/transformers/modeling_utils.pyä¸­çš„get_extended_attention_maskå‡½æ•°ã€‚

éƒ¨åˆ†ä»£ç è§ä¸‹é¢ã€‚


```python
def get_extended_attention_mask(self, attention_mask: Tensor, input_shape: Tuple[int], device: device) -> Tensor:
    if attention_mask.dim() == 3:
        extended_attention_mask = attention_mask[:, None, :, :]
    elif attention_mask.dim() == 2:
        # - if the model is a decoder, apply a causal mask in addition to the padding mask
        # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]
        if self.config.is_decoder: # bertä¸æ¶‰åŠdecoderï¼Œå¦‚æœéœ€è¦decoderæ—¶æ˜¯è¦è€ƒè™‘è¿™é‡Œçš„mask
            batch_size, seq_length = input_shape
            seq_ids = torch.arange(seq_length, device=device)
            causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]
            # in case past_key_values are used we need to add a prefix ones mask to the causal mask
            # causal and attention masks must have same type with pytorch version < 1.3
            causal_mask = causal_mask.to(attention_mask.dtype)

            if causal_mask.shape[1] < attention_mask.shape[1]:
                prefix_seq_len = attention_mask.shape[1] - causal_mask.shape[1]
                causal_mask = torch.cat(
                    [
                        torch.ones(
                            (batch_size, seq_length, prefix_seq_len), device=device, dtype=causal_mask.dtype
                        ),
                        causal_mask,
                    ],
                    axis=-1,
                )

            extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]
        else:
            extended_attention_mask = attention_mask[:, None, None, :]
    else:
        raise ValueError(
            "Wrong shape for input_ids (shape {}) or attention_mask (shape {})".format(
                input_shape, attention_mask.shape
            )
        )

    # Since attention_mask is 1.0 for positions we want to attend and 0.0 for
    # masked positions, this operation will create a tensor which is 0.0 for
    # positions we want to attend and -10000.0 for masked positions.
    # Since we are adding it to the raw scores before the softmax, this is
    # effectively the same as removing these entirely.
    extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility
    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0
    return extended_attention_mask
```

ä»£ç æ¯”è¾ƒå¤æ‚ï¼Œä¸è¿‡åŸç†å¾ˆç®€å•ã€‚

padding maskï¼Œåœ¨nlpä»»åŠ¡ä¸­ç”±äºä¸€ä¸ªbatchæ•°æ®ä¸­å¥å­é•¿çŸ­ä¸ä¸€ï¼Œæ‰€ä»¥éœ€è¦å¯¹ä¸€äº›å¥å­è¿›è¡Œpaddingï¼Œè€Œè¿™äº›paddingçš„æ•°æ®åœ¨åé¢è‡ªæ³¨æ„åŠ›è®¡ç®—ä¸Šæ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼Œæ‰€ä»¥åœ¨è®¡ç®—ä¸­è¦å¿½ç•¥paddingçš„å½±å“ã€‚

å…·ä½“å®ç°æ˜¯è§æºç ä¸­è¿™æ®µ
```
extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0
```
æŠŠpaddingä½ç½®ä¸Šçš„å€¼åŠ ä¸Šä¸€ä¸ªéå¸¸å¤§çš„è´Ÿæ•°ï¼Œè¿™æ ·ç»è¿‡softmaxè®¡ç®—åè¿™ä¸ªä½ç½®çš„æ¦‚è®ºæ— é™æ¥è¿‘é›¶ã€‚

sequence maskï¼Œåœ¨åšç”Ÿæˆé—®é¢˜æ—¶ï¼Œä¸ºäº†ä¸è®©æ¨¡å‹çœ‹åˆ°åé¢çš„æ ‡å‡†ç­”æ¡ˆï¼Œæ‰€ä»¥åœ¨é¢„æµ‹tä½ç½®è¯çš„æ—¶å€™ï¼ŒæŠŠtåé¢æ‰€æœ‰çš„è¯éƒ½maskæ‰ï¼Œå…·ä½“å®ç°æ˜¯é€šè¿‡ä¸€ä¸ªå¯¹è§’çŸ©é˜µå®ç°çš„ï¼Œæ­¤å¤„å°±ä¸ç»†è®²äº†ã€‚æ³¨æ„ç”±äºdecoderè¿‡ç¨‹ä¸­padding maskå’Œsequence maskéƒ½å­˜åœ¨ï¼Œæ‰€ä»¥ä¸Šé¢æºç æœ‰ä¸¤ä¸ªmaskæƒ³åŠ çš„è¿‡ç¨‹ã€‚

å¥½çš„ï¼Œæ•´ä¸ªBERTæ ¸å¿ƒæºç å·²ç»è®²å®Œäº†ï¼Œå¦‚æœåŒå­¦ä»¬åœ¨ç†è®ºçš„ç»†èŠ‚ä¸Šè¿˜æ˜¯æœ‰ä¸€äº›æ¨¡ç³Šï¼Œå¯ä»¥è¡¥å……é˜…è¯»[Transformeræ¨¡å‹æ·±åº¦è§£è¯»](https://zhuanlan.zhihu.com/p/104393915)ï¼Œè¯¥åšå®¢ä»Transformerçš„è§’åº¦è¯¦ç»†åšäº†è§£é‡Šï¼Œçœ‹å®Œåï¼Œå›å¤´åœ¨çœ‹çœ‹BERTçš„æºç ï¼Œæˆ‘ç›¸ä¿¡ç†è§£ä¼šè¿›ä¸€æ­¥åŠ æ·±ã€‚

# 6 æ¨¡å‹è¾“å…¥ä¹‹Embeddingå±‚

BERTæ¨¡å‹çš„è¾“å…¥ä¸ç®¡æ˜¯å•ä¸ªå¥å­è¿˜æ˜¯å¤šä¸ªå¥å­ï¼Œéƒ½ä¼šå°†å¥å­ä¸­çš„Tokenè½¬åŒ–æˆEmbeddingä¹‹åä¼ åˆ°æ¨¡å‹é‡Œï¼Œé‚£BERTçš„Embeddingæ˜¯æ€ä¹ˆåšçš„å‘¢ï¼Ÿå®ƒæ˜¯ç”±Token Embeddingsã€Segment Embeddingså’ŒPosition Embeddingsæƒ³åŠ ç»„æˆï¼Œå¦‚ä¸‹å›¾ã€‚

å…¶ä¸­ï¼š

1ï¼‰Token Embeddingsæ˜¯è¯å‘é‡ï¼Œæ˜¯å°†TokenåµŒå…¥åˆ°ä¸€ä¸ªç»´åº¦çš„ç©ºé—´ï¼ŒBERTéšç€ç»“æ„å±‚æ•°çš„å˜åŒ–ï¼Œåˆ†åˆ«é€‰å–äº†768ç»´å’Œ1024ç»´ã€‚åœ¨Tokençš„è¾“å…¥ä¸Šï¼ŒBERTä¹Ÿåšäº†ç‰¹æ®Šçš„å¤„ç†ï¼Œç¬¬ä¸€ä¸ªTokenæ˜¯ä¸€ä¸ªCLSçš„ç‰¹æ®Šå­—ç¬¦ï¼Œå¯ä»¥ç”¨äºä¸‹æ¸¸çš„ä»»åŠ¡ã€‚å¥å­å’Œå¥å­çš„ä¸­é—´ï¼Œä»¥åŠå¥å­çš„æœ«å°¾ä¼šæœ‰ä¸€ä¸ªç‰¹æ®Šçš„ç¬¦å·SEPï¼›

2ï¼‰Segment Embeddingsç”¨æ¥åŒºåˆ«ä¸¤ç§å¥å­ï¼Œå› ä¸ºé¢„è®­ç»ƒä¸å…‰åšLMè¿˜è¦åšä»¥ä¸¤ä¸ªå¥å­ä¸ºè¾“å…¥çš„åˆ†ç±»ä»»åŠ¡ï¼›

3ï¼‰Position Embeddingså’Œä¸Šä¸€ç« çš„Transformerä¸ä¸€æ ·ï¼Œä¸æ˜¯ä¸‰è§’å‡½æ•°è€Œæ˜¯ä¸€ä¸ªè·Ÿç€è®­ç»ƒå­¦å‡ºæ¥çš„å‘é‡ã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/8c8dc740398c4bb597fdf40b37f3443e8344dc0f65b4493984adde5fac6296ed" width="700" />


```python
class BertEmbeddings(nn.Module):
    """Construct the embeddings from word, position and token_type embeddings."""

    def __init__(self, config):
        super().__init__()
        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)
        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)
        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)

        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load
        # any TensorFlow checkpoint file
        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)
        self.dropout = nn.Dropout(config.hidden_dropout_prob)

        # position_ids (1, len position emb) is contiguous in memory and exported when serialized
        self.register_buffer("position_ids", torch.arange(config.max_position_embeddings).expand((1, -1)))
```

ä»¥ä¸Šä»£ç å°±æ˜¯BERT Embeddingå±‚çš„ä¸€äº›å®šä¹‰ï¼Œæœ€ç»ˆä¼šå°†ä¸‰ç§Embeddingæƒ³åŠ ã€‚

```
embeddings = inputs_embeds + position_embeddings + token_type_embeddings
```
åŒå­¦ä»¬æ˜¯ä¸æ˜¯è¿˜ä¼šæœ‰ä¸€äº›ç–‘æƒ‘ï¼Œä¸ºä»€ä¹ˆBERTçš„ä½ç½®ç¼–ç è¿™ä¹ˆç®€å•ç²—æš´ï¼Œå…³äºä¸€äº›ç›¸å…³æ¢è®¨ï¼Œå¯ä»¥é˜…è¯»[å¦‚ä½•ä¼˜é›…åœ°ç¼–ç æ–‡æœ¬ä¸­çš„ä½ç½®ä¿¡æ¯ï¼Ÿä¸‰ç§positional encodingæ–¹æ³•ç®€è¿°](https://zhuanlan.zhihu.com/p/121126531)ã€‚

# 7 æ¨¡å‹è¾“å‡ºå±‚ä¸CLS

å…³äºæ¨¡å‹çš„è¾“å‡ºå±‚ï¼Œå¤§å®¶å¯ä»¥å‚ç…§ä¸€ä¸‹æºç ã€‚å…·ä½“çš„ä½¿ç”¨ï¼Œä»¥åŠå…¶ä¸­çš„ä¸€äº›ç‰¹æ®Šç¬¦å·éƒ½ä¼šåœ¨åç»­è¯¾ç¨‹ä¸­è¯¦è§£ã€‚


```python
class BertPooler(nn.Module):
    # Pooleræ‹¿çš„æ˜¯ç¬¬ä¸€ä¸ªtokençš„æœ€ç»ˆè¾“å‡ºï¼Œä¹Ÿå°±æ˜¯CLSç‰¹æ®Šç¬¦å·çš„è¾“å‡º
    def __init__(self, config):
        super().__init__()
        self.dense = nn.Linear(config.hidden_size, config.hidden_size)
        self.activation = nn.Tanh()

    def forward(self, hidden_states):
        # We "pool" the model by simply taking the hidden state corresponding
        # to the first token.
        first_token_tensor = hidden_states[:, 0]
        pooled_output = self.dense(first_token_tensor)
        pooled_output = self.activation(pooled_output)
        return pooled_output
```

è‡³æ­¤æœ‰å…³BERTçš„æ ¸å¿ƒä»£ç å†…å®¹ä»‹ç»å°±ç»“æŸäº†ï¼Œå¤§å®¶ç»“åˆè¯¾ä¸Šçš„å†…å®¹ï¼Œå¤šå¤šç ”ç©¶æºç ï¼Œå¯¹BERTæŒæ¡ä¼šæ›´ä¸Šä¸€å±‚æ¥¼ã€‚

# 8 ä½œä¸š

## 8.1ä½œä¸šè¦æ±‚

> ä½œä¸šä¸€

ELMoçš„ç¼ºç‚¹æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ

> ä½œä¸šäºŒ

BERTé‡‡ç”¨äº†è¿ç§»å­¦ä¹ çš„æ€æƒ³ï¼Œå¦‚æœåœ¨ç›¸åŒçš„NLPä»»åŠ¡ä¸Šè¾¾åˆ°ä¼ ç»Ÿæ¨¡å‹ï¼ˆå¦‚RNNç­‰ï¼‰ä¸€æ ·çš„æ€§èƒ½æŒ‡æ ‡ï¼Œæ¯”å¦‚å‡†ç¡®åº¦éƒ½æ˜¯90%ï¼Œåœ¨å‡†å¤‡æ•°æ®æˆæœ¬ä¸Šæœ‰ä¼˜åŠ¿ä¹ˆï¼Œä»€ä¹ˆæ ·çš„ä¼˜åŠ¿ï¼Ÿ

> ä½œä¸šä¸‰

é—®ä¸ªé—®é¢˜ï¼Œå¤šå¤´æ³¨æ„åŠ›æ˜¯å¦‚ä½•å®ç°çš„ï¼Œå…·ä½“æ˜¯åœ¨å“ªä¸ªtensoråˆ‡åˆ†çš„å¤´ï¼Œä¸ºä»€ä¹ˆè¦å¤šå¤´ï¼Ÿ

> ä½œä¸šå››

ä¸ºä»€ä¹ˆBERTé‡Œé¢ç”¨çš„æ˜¯LNï¼Œè€Œä¸æ˜¯BNï¼Ÿ

## 8.2ä½œä¸šæäº¤å¤„

ä½œä¸šä¸€

ä½œä¸šäºŒ

ä½œä¸šä¸‰

ä½œä¸šå››


```python

```
